{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.linalg import fractional_matrix_power\n",
    "from yaspin import yaspin\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer(\n",
       "    (auto_model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): Pooling()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "bert_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model.max_seq_length = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1ce6acb6890>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 768\n",
    "init_query_embed_size = 768\n",
    "num_docs = 50\n",
    "batch_size = 10\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, n_h, input_features):\n",
    "        super().__init__()\n",
    "        W = torch.FloatTensor(input_features, n_h)\n",
    "        self.weights = torch.nn.Parameter(W)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        stdv = 1. / math.sqrt(self.weights.size(1))\n",
    "        self.weights.data.uniform_(-stdv, stdv)\n",
    "        bs = torch.FloatTensor(n_h)\n",
    "        self.bias = torch.nn.Parameter(bs)\n",
    "        self.bias.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "    def forward(self, nfs, A):\n",
    "        out = torch.matmul(nfs, self.weights)\n",
    "        out = torch.matmul(A, out)\n",
    "        out = out + self.bias\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmbiguityNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GCN(10, embed_size)\n",
    "        self.gcn2 = GCN(10, 10)\n",
    "        self.gcn3 = GCN(10,10)\n",
    "        self.dp = torch.nn.Dropout(p = 0.5)\n",
    "        self.dense1 = torch.nn.Linear(in_features = 500 + init_query_embed_size, out_features = 64)\n",
    "        self.dense2 = torch.nn.Linear(in_features = 64, out_features = 4)\n",
    "    \n",
    "    def forward(self, inputs, A, init_query):\n",
    "        out = self.gcn1(inputs, A)\n",
    "        out = self.dp(out)\n",
    "        out = self.gcn2(out, A)\n",
    "        out = self.dp(out)\n",
    "        out = self.gcn3(out, A)\n",
    "        out = self.dp(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = torch.cat((out, init_query), dim = 1)\n",
    "        out = self.dense1(out)\n",
    "        out = self.dense2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>initial_request</th>\n",
       "      <th>topic_desc</th>\n",
       "      <th>clarification_need</th>\n",
       "      <th>facet_id</th>\n",
       "      <th>facet_desc</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Tell me about Obama family tree.</td>\n",
       "      <td>Find information on President Barack Obama\\'s ...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0001</td>\n",
       "      <td>Find the TIME magazine photo essay \"Barack Oba...</td>\n",
       "      <td>Q00384</td>\n",
       "      <td>are you interested in seeing barack obamas family</td>\n",
       "      <td>yes am interested in obamas family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>102</td>\n",
       "      <td>What is Fickle Creek Farm</td>\n",
       "      <td>Find general information about Fickle Creek Fa...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0014</td>\n",
       "      <td>Find general information about Fickle Creek Fa...</td>\n",
       "      <td>Q00059</td>\n",
       "      <td>are you going to purchase anything there</td>\n",
       "      <td>i dont know yet i just want general info about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>105</td>\n",
       "      <td>Tell me about sonoma county medical services.</td>\n",
       "      <td>What medical services are available in Sonoma ...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0025</td>\n",
       "      <td>What medical services are available in Sonoma ...</td>\n",
       "      <td>Q00457</td>\n",
       "      <td>are you interested in the human services depar...</td>\n",
       "      <td>no i am looking for doctors or hospitals in so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>108</td>\n",
       "      <td>Tell me about of Ralph Owen Brester.</td>\n",
       "      <td>Find biographical information about Ralph Owen...</td>\n",
       "      <td>1</td>\n",
       "      <td>F0037</td>\n",
       "      <td>Find biographical information about Ralph Owen...</td>\n",
       "      <td>Q00297</td>\n",
       "      <td>are you interested in learning more about ralp...</td>\n",
       "      <td>yes and his biography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>109</td>\n",
       "      <td>I'm looking for information about mayo clinic ...</td>\n",
       "      <td>What medical services are available at the May...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0040</td>\n",
       "      <td>What medical services are available at the May...</td>\n",
       "      <td>Q00256</td>\n",
       "      <td>are you interested in jobs at mayo clinic jack...</td>\n",
       "      <td>no im interested in services provided at mayo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9113</th>\n",
       "      <td>234</td>\n",
       "      <td>tell me about dark chocolate health benefits</td>\n",
       "      <td>What are the health benefits associated with e...</td>\n",
       "      <td>1</td>\n",
       "      <td>F0539</td>\n",
       "      <td>What are the health benefits associated with e...</td>\n",
       "      <td>Q00430</td>\n",
       "      <td>are you interested in the different candles da...</td>\n",
       "      <td>no im more interested in the health benefits o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9127</th>\n",
       "      <td>238</td>\n",
       "      <td>Tell me bio of george bush sr.</td>\n",
       "      <td>Find biographies of US President George H.W. B...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0552</td>\n",
       "      <td>Find biographies of US President George H.W. B...</td>\n",
       "      <td>Q00402</td>\n",
       "      <td>are you interested in the 1992 presidential el...</td>\n",
       "      <td>yes i would like to know about george bush srs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9139</th>\n",
       "      <td>240</td>\n",
       "      <td>Tell me more about us presidents</td>\n",
       "      <td>Find a list of the full names of US presidents.</td>\n",
       "      <td>3</td>\n",
       "      <td>F0558</td>\n",
       "      <td>Find a list of the full names of US presidents.</td>\n",
       "      <td>Q00201</td>\n",
       "      <td>are you interested in finding out the middle n...</td>\n",
       "      <td>no i am interested in the names of all us pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9151</th>\n",
       "      <td>261</td>\n",
       "      <td>Tell me about folk remedies for a sore throat.</td>\n",
       "      <td>What folk remedies are there for soothing a so...</td>\n",
       "      <td>1</td>\n",
       "      <td>F0633</td>\n",
       "      <td>What folk remedies are there for soothing a so...</td>\n",
       "      <td>Q00208</td>\n",
       "      <td>are you interested in folk remedies from a spe...</td>\n",
       "      <td>no just any folk remedies for a sore throat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9163</th>\n",
       "      <td>295</td>\n",
       "      <td>How do you tie a Windsor knot?</td>\n",
       "      <td>How do you tie a Windsor knot?</td>\n",
       "      <td>1</td>\n",
       "      <td>F0752</td>\n",
       "      <td>How do you tie a Windsor knot?</td>\n",
       "      <td>Q00182</td>\n",
       "      <td>are you interested in different knot tying tec...</td>\n",
       "      <td>yes and windsor knot being the most specific t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic_id                                    initial_request  \\\n",
       "0            1                   Tell me about Obama family tree.   \n",
       "39         102                          What is Fickle Creek Farm   \n",
       "84         105      Tell me about sonoma county medical services.   \n",
       "120        108               Tell me about of Ralph Owen Brester.   \n",
       "159        109  I'm looking for information about mayo clinic ...   \n",
       "...        ...                                                ...   \n",
       "9113       234       tell me about dark chocolate health benefits   \n",
       "9127       238                     Tell me bio of george bush sr.   \n",
       "9139       240                   Tell me more about us presidents   \n",
       "9151       261     Tell me about folk remedies for a sore throat.   \n",
       "9163       295                     How do you tie a Windsor knot?   \n",
       "\n",
       "                                             topic_desc  clarification_need  \\\n",
       "0     Find information on President Barack Obama\\'s ...                   2   \n",
       "39    Find general information about Fickle Creek Fa...                   2   \n",
       "84    What medical services are available in Sonoma ...                   2   \n",
       "120   Find biographical information about Ralph Owen...                   1   \n",
       "159   What medical services are available at the May...                   2   \n",
       "...                                                 ...                 ...   \n",
       "9113  What are the health benefits associated with e...                   1   \n",
       "9127  Find biographies of US President George H.W. B...                   2   \n",
       "9139    Find a list of the full names of US presidents.                   3   \n",
       "9151  What folk remedies are there for soothing a so...                   1   \n",
       "9163                     How do you tie a Windsor knot?                   1   \n",
       "\n",
       "     facet_id                                         facet_desc question_id  \\\n",
       "0       F0001  Find the TIME magazine photo essay \"Barack Oba...      Q00384   \n",
       "39      F0014  Find general information about Fickle Creek Fa...      Q00059   \n",
       "84      F0025  What medical services are available in Sonoma ...      Q00457   \n",
       "120     F0037  Find biographical information about Ralph Owen...      Q00297   \n",
       "159     F0040  What medical services are available at the May...      Q00256   \n",
       "...       ...                                                ...         ...   \n",
       "9113    F0539  What are the health benefits associated with e...      Q00430   \n",
       "9127    F0552  Find biographies of US President George H.W. B...      Q00402   \n",
       "9139    F0558    Find a list of the full names of US presidents.      Q00201   \n",
       "9151    F0633  What folk remedies are there for soothing a so...      Q00208   \n",
       "9163    F0752                     How do you tie a Windsor knot?      Q00182   \n",
       "\n",
       "                                               question  \\\n",
       "0     are you interested in seeing barack obamas family   \n",
       "39             are you going to purchase anything there   \n",
       "84    are you interested in the human services depar...   \n",
       "120   are you interested in learning more about ralp...   \n",
       "159   are you interested in jobs at mayo clinic jack...   \n",
       "...                                                 ...   \n",
       "9113  are you interested in the different candles da...   \n",
       "9127  are you interested in the 1992 presidential el...   \n",
       "9139  are you interested in finding out the middle n...   \n",
       "9151  are you interested in folk remedies from a spe...   \n",
       "9163  are you interested in different knot tying tec...   \n",
       "\n",
       "                                                 answer  \n",
       "0                    yes am interested in obamas family  \n",
       "39    i dont know yet i just want general info about...  \n",
       "84    no i am looking for doctors or hospitals in so...  \n",
       "120                               yes and his biography  \n",
       "159   no im interested in services provided at mayo ...  \n",
       "...                                                 ...  \n",
       "9113  no im more interested in the health benefits o...  \n",
       "9127  yes i would like to know about george bush srs...  \n",
       "9139  no i am interested in the names of all us pres...  \n",
       "9151        no just any folk remedies for a sore throat  \n",
       "9163  yes and windsor knot being the most specific t...  \n",
       "\n",
       "[187 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests = pd.read_table('./data/train.tsv', sep = '\\t', header = 0).drop_duplicates('topic_id')\n",
    "requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>initial_request</th>\n",
       "      <th>topic_desc</th>\n",
       "      <th>clarification_need</th>\n",
       "      <th>facet_id</th>\n",
       "      <th>facet_desc</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Find me information about the Ritz Carlton Lak...</td>\n",
       "      <td>Find information about the Ritz Carlton resort...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0010</td>\n",
       "      <td>Find information about the Ritz Carlton resort...</td>\n",
       "      <td>Q00697</td>\n",
       "      <td>are you looking for a specific web site</td>\n",
       "      <td>yes for the ritz carlton resort at lake las vegas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>106</td>\n",
       "      <td>I'm looking for universal animal cuts reviews</td>\n",
       "      <td>Find testimonials of Universal Animal Cuts nut...</td>\n",
       "      <td>3</td>\n",
       "      <td>F0028</td>\n",
       "      <td>Find testimonials of Universal Animal Cuts nut...</td>\n",
       "      <td>Q01481</td>\n",
       "      <td>did universal animal cuts work for you</td>\n",
       "      <td>i need testimonials on the universal animal cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>107</td>\n",
       "      <td>tell me about cass county missouri</td>\n",
       "      <td>Find demographic information about Cass County...</td>\n",
       "      <td>3</td>\n",
       "      <td>F0031</td>\n",
       "      <td>Find demographic information about Cass County...</td>\n",
       "      <td>Q00086</td>\n",
       "      <td>are you interested in a list of homes for sale...</td>\n",
       "      <td>no i want demographic info for cass county mo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>114</td>\n",
       "      <td>Tell about an adobe indian house?</td>\n",
       "      <td>How does one build an adobe house?</td>\n",
       "      <td>2</td>\n",
       "      <td>F0063</td>\n",
       "      <td>How does one build an adobe house?</td>\n",
       "      <td>Q00057</td>\n",
       "      <td>are you going to purchase any specific product...</td>\n",
       "      <td>maybe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>123</td>\n",
       "      <td>What is von Willebrand Disease?</td>\n",
       "      <td>What is von Willebrand Disease?</td>\n",
       "      <td>3</td>\n",
       "      <td>F0100</td>\n",
       "      <td>What is von Willebrand Disease?</td>\n",
       "      <td>Q00284</td>\n",
       "      <td>are you interested in learning about treatment...</td>\n",
       "      <td>id like to know what it is first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>128</td>\n",
       "      <td>Tell me about atypical squamous cells</td>\n",
       "      <td>What do atypical squamous cells mean on a pap ...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0114</td>\n",
       "      <td>What do atypical squamous cells mean on a pap ...</td>\n",
       "      <td>Q00081</td>\n",
       "      <td>are you interested in a desciption of aytypica...</td>\n",
       "      <td>yes and it must be related to pap smear tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>133</td>\n",
       "      <td>all men are created equal</td>\n",
       "      <td>Who said \\\"all men are created equal\\\"?</td>\n",
       "      <td>2</td>\n",
       "      <td>F0134</td>\n",
       "      <td>Who said \"all men are created equal\"?</td>\n",
       "      <td>Q00796</td>\n",
       "      <td>are you looking for declaration of independenc...</td>\n",
       "      <td>i am looking for who said the qoute provided</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>139</td>\n",
       "      <td>Tell me more about Rocky Mountain News</td>\n",
       "      <td>discussion of the impending sale of the Rocky ...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0156</td>\n",
       "      <td>discussion of the impending sale of the Rocky ...</td>\n",
       "      <td>Q00334</td>\n",
       "      <td>are you interested in news archives</td>\n",
       "      <td>no i am intrested in the sale of arocky mounta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>142</td>\n",
       "      <td>Find me information about the sales tax in Ill...</td>\n",
       "      <td>information about the sales tax in Illinois: w...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0170</td>\n",
       "      <td>information about the sales tax in Illinois: w...</td>\n",
       "      <td>Q00241</td>\n",
       "      <td>are you interested in how the illinois state t...</td>\n",
       "      <td>no i would like to know the rate and what it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>164</td>\n",
       "      <td>I'm looking for information on hobby stores</td>\n",
       "      <td>What hobby stores carry trains?</td>\n",
       "      <td>4</td>\n",
       "      <td>F0259</td>\n",
       "      <td>What hobby stores carry trains?</td>\n",
       "      <td>Q00659</td>\n",
       "      <td>are you looking for a radiocontrolled plane</td>\n",
       "      <td>no im looking for trains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>165</td>\n",
       "      <td>I’m looking for blue throated hummingbird</td>\n",
       "      <td>Find a picture of a blue-throated hummingbird.</td>\n",
       "      <td>3</td>\n",
       "      <td>F0263</td>\n",
       "      <td>Find a picture of a blue-throated hummingbird.</td>\n",
       "      <td>Q00049</td>\n",
       "      <td>are you curious about the size</td>\n",
       "      <td>no just show me a picture of one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>166</td>\n",
       "      <td>Tell me information about computer programming.</td>\n",
       "      <td>What type of careers are there for computer pr...</td>\n",
       "      <td>3</td>\n",
       "      <td>F0267</td>\n",
       "      <td>What type of careers are there for computer pr...</td>\n",
       "      <td>Q00079</td>\n",
       "      <td>are you interested in a coding bootcamp</td>\n",
       "      <td>no i want to know what career options programm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>169</td>\n",
       "      <td>What should I know about the civil war</td>\n",
       "      <td>What were the major battles in the US civil war?</td>\n",
       "      <td>4</td>\n",
       "      <td>F0283</td>\n",
       "      <td>What were the major battles in the US civil war?</td>\n",
       "      <td>Q00605</td>\n",
       "      <td>are you looking for a confederate victory</td>\n",
       "      <td>all of the major battles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>174</td>\n",
       "      <td>I want to learn about rock art.</td>\n",
       "      <td>Where can I learn about rock painting or buy a...</td>\n",
       "      <td>4</td>\n",
       "      <td>F0308</td>\n",
       "      <td>Where can I learn about rock painting or buy a...</td>\n",
       "      <td>Q00058</td>\n",
       "      <td>are you going to purchase any specific tools</td>\n",
       "      <td>yes and i need to learn about rock painting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>18</td>\n",
       "      <td>I'm looking for a wedding budget calculator</td>\n",
       "      <td>I\\'m looking for information on planning and b...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0331</td>\n",
       "      <td>I want to find online guides, tips, and checkl...</td>\n",
       "      <td>Q00102</td>\n",
       "      <td>are you interested in a service for wedding bu...</td>\n",
       "      <td>no i want to find something online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>190</td>\n",
       "      <td>Find Brooks Brothers clearance.</td>\n",
       "      <td>Find Brooks Brothers online promotional coupons.</td>\n",
       "      <td>2</td>\n",
       "      <td>F0374</td>\n",
       "      <td>Find Brooks Brothers online promotional coupons.</td>\n",
       "      <td>Q00159</td>\n",
       "      <td>are you interested in brooks brothers clearanc...</td>\n",
       "      <td>no i need brooks brothers online promotional c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>191</td>\n",
       "      <td>When can I see Churchil Downs</td>\n",
       "      <td>Find information on the racing schedule at Chu...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0377</td>\n",
       "      <td>Find information on the racing schedule at Chu...</td>\n",
       "      <td>Q00100</td>\n",
       "      <td>are you interested in a schedule of events fro...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>193</td>\n",
       "      <td>Where should I order dog clean-up bags</td>\n",
       "      <td>Can I order dog clean-up bags online?</td>\n",
       "      <td>3</td>\n",
       "      <td>F0384</td>\n",
       "      <td>Can I order dog clean-up bags online?</td>\n",
       "      <td>Q00052</td>\n",
       "      <td>are you disposing of your dog waste at home or...</td>\n",
       "      <td>no i need to know if i can buy dog clean up ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>195</td>\n",
       "      <td>Where can I buy pressure washers?</td>\n",
       "      <td>Where can I buy replacement parts for pressure...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0390</td>\n",
       "      <td>Where can I buy replacement parts for pressure...</td>\n",
       "      <td>Q01084</td>\n",
       "      <td>are you looking for the nearest location to bu...</td>\n",
       "      <td>no i need parts for a pressure washer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>200</td>\n",
       "      <td>Find information on ontario california airport.</td>\n",
       "      <td>Find flight information for the Ontario, CA ai...</td>\n",
       "      <td>3</td>\n",
       "      <td>F0414</td>\n",
       "      <td>Find flight information for the Ontario, CA ai...</td>\n",
       "      <td>Q01194</td>\n",
       "      <td>are you planning to take a trip on ontario or ...</td>\n",
       "      <td>i just want to find flight information for ota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>24</td>\n",
       "      <td>tell me about diversity</td>\n",
       "      <td>Find information on diversity, both culturally...</td>\n",
       "      <td>4</td>\n",
       "      <td>F0554</td>\n",
       "      <td>How is workplace diversity achieved and managed?</td>\n",
       "      <td>Q00609</td>\n",
       "      <td>are you looking for a definition of diversity</td>\n",
       "      <td>i want to know more about workplace diversity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>25</td>\n",
       "      <td>Tell me more about Euclid</td>\n",
       "      <td>Find information on the Greek mathematician Eu...</td>\n",
       "      <td>4</td>\n",
       "      <td>F0587</td>\n",
       "      <td>Find information on the Greek mathematician Eu...</td>\n",
       "      <td>Q00282</td>\n",
       "      <td>are you interested in learning about the greek...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>27</td>\n",
       "      <td>Tell me about Starbucks.</td>\n",
       "      <td>Find information about the coffee company Star...</td>\n",
       "      <td>3</td>\n",
       "      <td>F0647</td>\n",
       "      <td>Take me to the Starbucks homepage.</td>\n",
       "      <td>Q00112</td>\n",
       "      <td>are you interested in a specific nutritional i...</td>\n",
       "      <td>no i am trying to go to the starbucks home page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>35</td>\n",
       "      <td>Find information on Hoboken</td>\n",
       "      <td>Find information on the city of Hoboken, New J...</td>\n",
       "      <td>3</td>\n",
       "      <td>F0791</td>\n",
       "      <td>Find restaurants in Hoboken.</td>\n",
       "      <td>Q00009</td>\n",
       "      <td>are interested in the nightlife here</td>\n",
       "      <td>i am more interested in finding retaurants in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>37</td>\n",
       "      <td>Tell me about pampered chef</td>\n",
       "      <td>Find out about hosting a cooking show from The...</td>\n",
       "      <td>3</td>\n",
       "      <td>F0799</td>\n",
       "      <td>How do I host a Pampered Chef cooking show?</td>\n",
       "      <td>Q00999</td>\n",
       "      <td>are you looking for reviews related to the pam...</td>\n",
       "      <td>no i am interested in find out what is the pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>45</td>\n",
       "      <td>Give me information on solar panels.</td>\n",
       "      <td>Find information about solar panels and compan...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0835</td>\n",
       "      <td>What kinds of solar panels and photovoltaic ce...</td>\n",
       "      <td>Q00695</td>\n",
       "      <td>are you looking for a specific type of solar p...</td>\n",
       "      <td>yes also what photovoltaic cells are there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>71</td>\n",
       "      <td>Find information about living in India.</td>\n",
       "      <td>Find information about living in India.</td>\n",
       "      <td>3</td>\n",
       "      <td>F0949</td>\n",
       "      <td>Find information about buying real estate in I...</td>\n",
       "      <td>Q00161</td>\n",
       "      <td>are you interested in buying a house in india</td>\n",
       "      <td>i am more intrested in real estate in general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>74</td>\n",
       "      <td>Tell me about kiwi</td>\n",
       "      <td>Find information on kiwi fruit.</td>\n",
       "      <td>3</td>\n",
       "      <td>F0960</td>\n",
       "      <td>Find information on kiwi fruit.</td>\n",
       "      <td>Q00247</td>\n",
       "      <td>are you interested in images of the kiwi fruit</td>\n",
       "      <td>no id like to know more information about the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>8</td>\n",
       "      <td>I want to know about appraisals.</td>\n",
       "      <td>How are home values appraised? I want to know ...</td>\n",
       "      <td>4</td>\n",
       "      <td>F0985</td>\n",
       "      <td>What companies can give an appraisal of my hom...</td>\n",
       "      <td>Q00706</td>\n",
       "      <td>are you looking for a type of appraiser</td>\n",
       "      <td>im looking for nearby companies that do home a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>85</td>\n",
       "      <td>Find information from the milwaukee journal se...</td>\n",
       "      <td>Find information from the Milwaukee Journal Se...</td>\n",
       "      <td>3</td>\n",
       "      <td>F1004</td>\n",
       "      <td>Find the Milwaukee Journal Sentinel web site.</td>\n",
       "      <td>Q00125</td>\n",
       "      <td>are you interested in a subscription to the mi...</td>\n",
       "      <td>i dont know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>214</td>\n",
       "      <td>What does the US capital gains tax rate consis...</td>\n",
       "      <td>What does the US capital tax rate consist of a...</td>\n",
       "      <td>1</td>\n",
       "      <td>F0481</td>\n",
       "      <td>What does the US capital tax rate consist of a...</td>\n",
       "      <td>Q01559</td>\n",
       "      <td>do you like to know about shortterm capital ga...</td>\n",
       "      <td>i don know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>219</td>\n",
       "      <td>What was the name of Elvis Presley's home?</td>\n",
       "      <td>What was the name of Elvis Presley's home?</td>\n",
       "      <td>1</td>\n",
       "      <td>F0496</td>\n",
       "      <td>What was the name of Elvis Presley's home?</td>\n",
       "      <td>Q00518</td>\n",
       "      <td>are you interested in touring elvis presleys home</td>\n",
       "      <td>no i just would like to know the name of it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>229</td>\n",
       "      <td>Fine me beef stroganoff recipe</td>\n",
       "      <td>Find complete (not partial) recipes for beef s...</td>\n",
       "      <td>1</td>\n",
       "      <td>F0526</td>\n",
       "      <td>Find complete (not partial) recipes for beef s...</td>\n",
       "      <td>Q01476</td>\n",
       "      <td>can you cook from scratch</td>\n",
       "      <td>i want a list of recipes for beef stroganoff s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>250</td>\n",
       "      <td>What are problems with ford edge?</td>\n",
       "      <td>What problems have afflicted the Ford Edge car...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0590</td>\n",
       "      <td>What problems have afflicted the Ford Edge car...</td>\n",
       "      <td>Q00061</td>\n",
       "      <td>are you having electrical mechanical or mainte...</td>\n",
       "      <td>no i just want to know the problems with the car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>252</td>\n",
       "      <td>Tell me about history of orcas island</td>\n",
       "      <td>Looking for any historical information related...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0592</td>\n",
       "      <td>Looking for any historical information related...</td>\n",
       "      <td>Q00352</td>\n",
       "      <td>are you interested in proeuropean history of o...</td>\n",
       "      <td>yes show me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>262</td>\n",
       "      <td>Find more information about baldness cure</td>\n",
       "      <td>Find cures for baldness (other than hair repla...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0634</td>\n",
       "      <td>Find cures for baldness (other than hair repla...</td>\n",
       "      <td>Q00073</td>\n",
       "      <td>are you interested in a balding cure for men o...</td>\n",
       "      <td>im looking for cures in general thise that don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>283</td>\n",
       "      <td>Find information on hayrides in pa</td>\n",
       "      <td>Where can I go on a hay ride in Pennsylvania?</td>\n",
       "      <td>2</td>\n",
       "      <td>F0710</td>\n",
       "      <td>Where can I go on a hay ride in Pennsylvania?</td>\n",
       "      <td>Q00082</td>\n",
       "      <td>are you interested in a haunted hayride in pen...</td>\n",
       "      <td>yes but i would also like information about al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>287</td>\n",
       "      <td>What are treatments for carotid cavernous fist...</td>\n",
       "      <td>What treatments are available for CCFT, caroti...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0716</td>\n",
       "      <td>What treatments are available for CCFT, caroti...</td>\n",
       "      <td>Q00668</td>\n",
       "      <td>are you looking for a specific carotid caverno...</td>\n",
       "      <td>id like to know about the available options fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>293</td>\n",
       "      <td>Tell me about the educational advantages of so...</td>\n",
       "      <td>What are the educational benefits of social ne...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0746</td>\n",
       "      <td>What are the educational benefits of social ne...</td>\n",
       "      <td>Q00016</td>\n",
       "      <td>are there any specific educational advantages ...</td>\n",
       "      <td>yes i do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>110</td>\n",
       "      <td>where to go if I made a crime in Brazil</td>\n",
       "      <td>What are the boundaries of the political juris...</td>\n",
       "      <td>3</td>\n",
       "      <td>F0050</td>\n",
       "      <td>What are the boundaries of the political juris...</td>\n",
       "      <td>Q01187</td>\n",
       "      <td>are you planning a trip to brazil</td>\n",
       "      <td>i dont know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>118</td>\n",
       "      <td>What is Poem in Your Pocket Day?</td>\n",
       "      <td>What is \\\"Poem in Your Pocket Day\\\"?</td>\n",
       "      <td>2</td>\n",
       "      <td>F0078</td>\n",
       "      <td>What is \"Poem in Your Pocket Day\"?</td>\n",
       "      <td>Q00414</td>\n",
       "      <td>are you interested in the canadian holiday</td>\n",
       "      <td>maybe im not sure what it is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>126</td>\n",
       "      <td>Find me a map of the US Capitol</td>\n",
       "      <td>Find a map of the inside of the US Capitol.</td>\n",
       "      <td>2</td>\n",
       "      <td>F0110</td>\n",
       "      <td>Find a map of the inside of the US Capitol.</td>\n",
       "      <td>Q00087</td>\n",
       "      <td>are you interested in a map of capitol hill</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>152</td>\n",
       "      <td>How to cure angular cheilitis</td>\n",
       "      <td>What home remedies are there for angular cheil...</td>\n",
       "      <td>3</td>\n",
       "      <td>F0206</td>\n",
       "      <td>What home remedies are there for angular cheil...</td>\n",
       "      <td>Q00008</td>\n",
       "      <td>are asking what the symptoms are for angular c...</td>\n",
       "      <td>no i want home remedies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>20</td>\n",
       "      <td>Tell me about defender</td>\n",
       "      <td>I\\'m looking for the homepage of Windows Defen...</td>\n",
       "      <td>4</td>\n",
       "      <td>F0410</td>\n",
       "      <td>Find information on the Land Rover Defender sp...</td>\n",
       "      <td>Q00459</td>\n",
       "      <td>are you interested in the isfj personality type</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>44</td>\n",
       "      <td>Find me map of USA</td>\n",
       "      <td>Find maps of the United States.</td>\n",
       "      <td>2</td>\n",
       "      <td>F0830</td>\n",
       "      <td>Find US road maps.</td>\n",
       "      <td>Q00080</td>\n",
       "      <td>are you interested in a current map of the uni...</td>\n",
       "      <td>yes especially road maps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>51</td>\n",
       "      <td>Tell me more about horse hooves</td>\n",
       "      <td>Find information about horse hooves, their car...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0858</td>\n",
       "      <td>Find information about horses' hooves and how ...</td>\n",
       "      <td>Q00025</td>\n",
       "      <td>are you asking about a horses feet</td>\n",
       "      <td>yes about horse hooves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>79</td>\n",
       "      <td>tell me about Voyager</td>\n",
       "      <td>Find information about the NASA Voyager spacec...</td>\n",
       "      <td>4</td>\n",
       "      <td>F0981</td>\n",
       "      <td>Find the homepage for the NASA Voyager mission.</td>\n",
       "      <td>Q00453</td>\n",
       "      <td>are you interested in the history of the voyager</td>\n",
       "      <td>no just take me to the homepage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>83</td>\n",
       "      <td>tell me about memory</td>\n",
       "      <td>Find information about human memory.</td>\n",
       "      <td>4</td>\n",
       "      <td>F0998</td>\n",
       "      <td>Find information about human memory.</td>\n",
       "      <td>Q00176</td>\n",
       "      <td>are you interested in computer memory</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>256</td>\n",
       "      <td>Who is the patron saint of mental illness?</td>\n",
       "      <td>Who is the patron saint of mental illness?</td>\n",
       "      <td>1</td>\n",
       "      <td>F0609</td>\n",
       "      <td>Who is the patron saint of mental illness?</td>\n",
       "      <td>Q00304</td>\n",
       "      <td>are you interested in learning the back story ...</td>\n",
       "      <td>im interested in learning who it is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305</th>\n",
       "      <td>292</td>\n",
       "      <td>i'm interested in history of the electronic me...</td>\n",
       "      <td>Find information on how the electronic medical...</td>\n",
       "      <td>3</td>\n",
       "      <td>F0745</td>\n",
       "      <td>Find information on how the electronic medical...</td>\n",
       "      <td>Q00118</td>\n",
       "      <td>are you interested in a specific time when ele...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic_id                                    initial_request  \\\n",
       "0          101  Find me information about the Ritz Carlton Lak...   \n",
       "60         106      I'm looking for universal animal cuts reviews   \n",
       "102        107                 tell me about cass county missouri   \n",
       "192        114                  Tell about an adobe indian house?   \n",
       "231        123                    What is von Willebrand Disease?   \n",
       "267        128              Tell me about atypical squamous cells   \n",
       "303        133                          all men are created equal   \n",
       "378        139             Tell me more about Rocky Mountain News   \n",
       "426        142  Find me information about the sales tax in Ill...   \n",
       "471        164        I'm looking for information on hobby stores   \n",
       "539        165          I’m looking for blue throated hummingbird   \n",
       "607        166    Tell me information about computer programming.   \n",
       "677        169             What should I know about the civil war   \n",
       "725        174                    I want to learn about rock art.   \n",
       "800         18        I'm looking for a wedding budget calculator   \n",
       "870        190                    Find Brooks Brothers clearance.   \n",
       "915        191                      When can I see Churchil Downs   \n",
       "967        193             Where should I order dog clean-up bags   \n",
       "1018       195                  Where can I buy pressure washers?   \n",
       "1066       200    Find information on ontario california airport.   \n",
       "1142        24                            tell me about diversity   \n",
       "1198        25                          Tell me more about Euclid   \n",
       "1237        27                           Tell me about Starbucks.   \n",
       "1322        35                        Find information on Hoboken   \n",
       "1406        37                        Tell me about pampered chef   \n",
       "1458        45               Give me information on solar panels.   \n",
       "1488        71            Find information about living in India.   \n",
       "1548        74                                 Tell me about kiwi   \n",
       "1587         8                   I want to know about appraisals.   \n",
       "1639        85  Find information from the milwaukee journal se...   \n",
       "1695       214  What does the US capital gains tax rate consis...   \n",
       "1708       219         What was the name of Elvis Presley's home?   \n",
       "1720       229                     Fine me beef stroganoff recipe   \n",
       "1732       250                  What are problems with ford edge?   \n",
       "1745       252              Tell me about history of orcas island   \n",
       "1757       262          Find more information about baldness cure   \n",
       "1769       283                 Find information on hayrides in pa   \n",
       "1781       287  What are treatments for carotid cavernous fist...   \n",
       "1790       293  Tell me about the educational advantages of so...   \n",
       "1802       110            where to go if I made a crime in Brazil   \n",
       "1847       118                   What is Poem in Your Pocket Day?   \n",
       "1895       126                    Find me a map of the US Capitol   \n",
       "1923       152                      How to cure angular cheilitis   \n",
       "1975        20                             Tell me about defender   \n",
       "2035        44                                 Find me map of USA   \n",
       "2120        51                    Tell me more about horse hooves   \n",
       "2195        79                              tell me about Voyager   \n",
       "2251        83                               tell me about memory   \n",
       "2293       256         Who is the patron saint of mental illness?   \n",
       "2305       292  i'm interested in history of the electronic me...   \n",
       "\n",
       "                                             topic_desc  clarification_need  \\\n",
       "0     Find information about the Ritz Carlton resort...                   2   \n",
       "60    Find testimonials of Universal Animal Cuts nut...                   3   \n",
       "102   Find demographic information about Cass County...                   3   \n",
       "192                  How does one build an adobe house?                   2   \n",
       "231                     What is von Willebrand Disease?                   3   \n",
       "267   What do atypical squamous cells mean on a pap ...                   2   \n",
       "303             Who said \\\"all men are created equal\\\"?                   2   \n",
       "378   discussion of the impending sale of the Rocky ...                   2   \n",
       "426   information about the sales tax in Illinois: w...                   2   \n",
       "471                     What hobby stores carry trains?                   4   \n",
       "539      Find a picture of a blue-throated hummingbird.                   3   \n",
       "607   What type of careers are there for computer pr...                   3   \n",
       "677    What were the major battles in the US civil war?                   4   \n",
       "725   Where can I learn about rock painting or buy a...                   4   \n",
       "800   I\\'m looking for information on planning and b...                   2   \n",
       "870    Find Brooks Brothers online promotional coupons.                   2   \n",
       "915   Find information on the racing schedule at Chu...                   2   \n",
       "967               Can I order dog clean-up bags online?                   3   \n",
       "1018  Where can I buy replacement parts for pressure...                   2   \n",
       "1066  Find flight information for the Ontario, CA ai...                   3   \n",
       "1142  Find information on diversity, both culturally...                   4   \n",
       "1198  Find information on the Greek mathematician Eu...                   4   \n",
       "1237  Find information about the coffee company Star...                   3   \n",
       "1322  Find information on the city of Hoboken, New J...                   3   \n",
       "1406  Find out about hosting a cooking show from The...                   3   \n",
       "1458  Find information about solar panels and compan...                   2   \n",
       "1488            Find information about living in India.                   3   \n",
       "1548                    Find information on kiwi fruit.                   3   \n",
       "1587  How are home values appraised? I want to know ...                   4   \n",
       "1639  Find information from the Milwaukee Journal Se...                   3   \n",
       "1695  What does the US capital tax rate consist of a...                   1   \n",
       "1708         What was the name of Elvis Presley's home?                   1   \n",
       "1720  Find complete (not partial) recipes for beef s...                   1   \n",
       "1732  What problems have afflicted the Ford Edge car...                   2   \n",
       "1745  Looking for any historical information related...                   2   \n",
       "1757  Find cures for baldness (other than hair repla...                   2   \n",
       "1769      Where can I go on a hay ride in Pennsylvania?                   2   \n",
       "1781  What treatments are available for CCFT, caroti...                   2   \n",
       "1790  What are the educational benefits of social ne...                   2   \n",
       "1802  What are the boundaries of the political juris...                   3   \n",
       "1847               What is \\\"Poem in Your Pocket Day\\\"?                   2   \n",
       "1895        Find a map of the inside of the US Capitol.                   2   \n",
       "1923  What home remedies are there for angular cheil...                   3   \n",
       "1975  I\\'m looking for the homepage of Windows Defen...                   4   \n",
       "2035                    Find maps of the United States.                   2   \n",
       "2120  Find information about horse hooves, their car...                   2   \n",
       "2195  Find information about the NASA Voyager spacec...                   4   \n",
       "2251               Find information about human memory.                   4   \n",
       "2293         Who is the patron saint of mental illness?                   1   \n",
       "2305  Find information on how the electronic medical...                   3   \n",
       "\n",
       "     facet_id                                         facet_desc question_id  \\\n",
       "0       F0010  Find information about the Ritz Carlton resort...      Q00697   \n",
       "60      F0028  Find testimonials of Universal Animal Cuts nut...      Q01481   \n",
       "102     F0031  Find demographic information about Cass County...      Q00086   \n",
       "192     F0063                 How does one build an adobe house?      Q00057   \n",
       "231     F0100                    What is von Willebrand Disease?      Q00284   \n",
       "267     F0114  What do atypical squamous cells mean on a pap ...      Q00081   \n",
       "303     F0134              Who said \"all men are created equal\"?      Q00796   \n",
       "378     F0156  discussion of the impending sale of the Rocky ...      Q00334   \n",
       "426     F0170  information about the sales tax in Illinois: w...      Q00241   \n",
       "471     F0259                    What hobby stores carry trains?      Q00659   \n",
       "539     F0263     Find a picture of a blue-throated hummingbird.      Q00049   \n",
       "607     F0267  What type of careers are there for computer pr...      Q00079   \n",
       "677     F0283   What were the major battles in the US civil war?      Q00605   \n",
       "725     F0308  Where can I learn about rock painting or buy a...      Q00058   \n",
       "800     F0331  I want to find online guides, tips, and checkl...      Q00102   \n",
       "870     F0374   Find Brooks Brothers online promotional coupons.      Q00159   \n",
       "915     F0377  Find information on the racing schedule at Chu...      Q00100   \n",
       "967     F0384              Can I order dog clean-up bags online?      Q00052   \n",
       "1018    F0390  Where can I buy replacement parts for pressure...      Q01084   \n",
       "1066    F0414  Find flight information for the Ontario, CA ai...      Q01194   \n",
       "1142    F0554   How is workplace diversity achieved and managed?      Q00609   \n",
       "1198    F0587  Find information on the Greek mathematician Eu...      Q00282   \n",
       "1237    F0647                 Take me to the Starbucks homepage.      Q00112   \n",
       "1322    F0791                       Find restaurants in Hoboken.      Q00009   \n",
       "1406    F0799        How do I host a Pampered Chef cooking show?      Q00999   \n",
       "1458    F0835  What kinds of solar panels and photovoltaic ce...      Q00695   \n",
       "1488    F0949  Find information about buying real estate in I...      Q00161   \n",
       "1548    F0960                    Find information on kiwi fruit.      Q00247   \n",
       "1587    F0985  What companies can give an appraisal of my hom...      Q00706   \n",
       "1639    F1004      Find the Milwaukee Journal Sentinel web site.      Q00125   \n",
       "1695    F0481  What does the US capital tax rate consist of a...      Q01559   \n",
       "1708    F0496         What was the name of Elvis Presley's home?      Q00518   \n",
       "1720    F0526  Find complete (not partial) recipes for beef s...      Q01476   \n",
       "1732    F0590  What problems have afflicted the Ford Edge car...      Q00061   \n",
       "1745    F0592  Looking for any historical information related...      Q00352   \n",
       "1757    F0634  Find cures for baldness (other than hair repla...      Q00073   \n",
       "1769    F0710      Where can I go on a hay ride in Pennsylvania?      Q00082   \n",
       "1781    F0716  What treatments are available for CCFT, caroti...      Q00668   \n",
       "1790    F0746  What are the educational benefits of social ne...      Q00016   \n",
       "1802    F0050  What are the boundaries of the political juris...      Q01187   \n",
       "1847    F0078                 What is \"Poem in Your Pocket Day\"?      Q00414   \n",
       "1895    F0110        Find a map of the inside of the US Capitol.      Q00087   \n",
       "1923    F0206  What home remedies are there for angular cheil...      Q00008   \n",
       "1975    F0410  Find information on the Land Rover Defender sp...      Q00459   \n",
       "2035    F0830                                 Find US road maps.      Q00080   \n",
       "2120    F0858  Find information about horses' hooves and how ...      Q00025   \n",
       "2195    F0981    Find the homepage for the NASA Voyager mission.      Q00453   \n",
       "2251    F0998               Find information about human memory.      Q00176   \n",
       "2293    F0609         Who is the patron saint of mental illness?      Q00304   \n",
       "2305    F0745  Find information on how the electronic medical...      Q00118   \n",
       "\n",
       "                                               question  \\\n",
       "0               are you looking for a specific web site   \n",
       "60               did universal animal cuts work for you   \n",
       "102   are you interested in a list of homes for sale...   \n",
       "192   are you going to purchase any specific product...   \n",
       "231   are you interested in learning about treatment...   \n",
       "267   are you interested in a desciption of aytypica...   \n",
       "303   are you looking for declaration of independenc...   \n",
       "378                 are you interested in news archives   \n",
       "426   are you interested in how the illinois state t...   \n",
       "471         are you looking for a radiocontrolled plane   \n",
       "539                      are you curious about the size   \n",
       "607             are you interested in a coding bootcamp   \n",
       "677           are you looking for a confederate victory   \n",
       "725        are you going to purchase any specific tools   \n",
       "800   are you interested in a service for wedding bu...   \n",
       "870   are you interested in brooks brothers clearanc...   \n",
       "915   are you interested in a schedule of events fro...   \n",
       "967   are you disposing of your dog waste at home or...   \n",
       "1018  are you looking for the nearest location to bu...   \n",
       "1066  are you planning to take a trip on ontario or ...   \n",
       "1142      are you looking for a definition of diversity   \n",
       "1198  are you interested in learning about the greek...   \n",
       "1237  are you interested in a specific nutritional i...   \n",
       "1322               are interested in the nightlife here   \n",
       "1406  are you looking for reviews related to the pam...   \n",
       "1458  are you looking for a specific type of solar p...   \n",
       "1488      are you interested in buying a house in india   \n",
       "1548     are you interested in images of the kiwi fruit   \n",
       "1587            are you looking for a type of appraiser   \n",
       "1639  are you interested in a subscription to the mi...   \n",
       "1695  do you like to know about shortterm capital ga...   \n",
       "1708  are you interested in touring elvis presleys home   \n",
       "1720                          can you cook from scratch   \n",
       "1732  are you having electrical mechanical or mainte...   \n",
       "1745  are you interested in proeuropean history of o...   \n",
       "1757  are you interested in a balding cure for men o...   \n",
       "1769  are you interested in a haunted hayride in pen...   \n",
       "1781  are you looking for a specific carotid caverno...   \n",
       "1790  are there any specific educational advantages ...   \n",
       "1802                  are you planning a trip to brazil   \n",
       "1847         are you interested in the canadian holiday   \n",
       "1895        are you interested in a map of capitol hill   \n",
       "1923  are asking what the symptoms are for angular c...   \n",
       "1975    are you interested in the isfj personality type   \n",
       "2035  are you interested in a current map of the uni...   \n",
       "2120                 are you asking about a horses feet   \n",
       "2195   are you interested in the history of the voyager   \n",
       "2251              are you interested in computer memory   \n",
       "2293  are you interested in learning the back story ...   \n",
       "2305  are you interested in a specific time when ele...   \n",
       "\n",
       "                                                 answer  \n",
       "0     yes for the ritz carlton resort at lake las vegas  \n",
       "60    i need testimonials on the universal animal cu...  \n",
       "102       no i want demographic info for cass county mo  \n",
       "192                                               maybe  \n",
       "231                    id like to know what it is first  \n",
       "267       yes and it must be related to pap smear tests  \n",
       "303        i am looking for who said the qoute provided  \n",
       "378   no i am intrested in the sale of arocky mounta...  \n",
       "426   no i would like to know the rate and what it i...  \n",
       "471                            no im looking for trains  \n",
       "539                    no just show me a picture of one  \n",
       "607   no i want to know what career options programm...  \n",
       "677                            all of the major battles  \n",
       "725         yes and i need to learn about rock painting  \n",
       "800                  no i want to find something online  \n",
       "870   no i need brooks brothers online promotional c...  \n",
       "915                                                 yes  \n",
       "967   no i need to know if i can buy dog clean up ba...  \n",
       "1018              no i need parts for a pressure washer  \n",
       "1066  i just want to find flight information for ota...  \n",
       "1142      i want to know more about workplace diversity  \n",
       "1198                                                yes  \n",
       "1237    no i am trying to go to the starbucks home page  \n",
       "1322  i am more interested in finding retaurants in ...  \n",
       "1406  no i am interested in find out what is the pro...  \n",
       "1458         yes also what photovoltaic cells are there  \n",
       "1488      i am more intrested in real estate in general  \n",
       "1548  no id like to know more information about the ...  \n",
       "1587  im looking for nearby companies that do home a...  \n",
       "1639                                        i dont know  \n",
       "1695                                         i don know  \n",
       "1708        no i just would like to know the name of it  \n",
       "1720  i want a list of recipes for beef stroganoff s...  \n",
       "1732   no i just want to know the problems with the car  \n",
       "1745                                        yes show me  \n",
       "1757  im looking for cures in general thise that don...  \n",
       "1769  yes but i would also like information about al...  \n",
       "1781  id like to know about the available options fo...  \n",
       "1790                                           yes i do  \n",
       "1802                                        i dont know  \n",
       "1847                       maybe im not sure what it is  \n",
       "1895                                                yes  \n",
       "1923                            no i want home remedies  \n",
       "1975                                                 no  \n",
       "2035                           yes especially road maps  \n",
       "2120                             yes about horse hooves  \n",
       "2195                    no just take me to the homepage  \n",
       "2251                                                 no  \n",
       "2293                im interested in learning who it is  \n",
       "2305                                                yes  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdev = pd.read_table('./data/dev.tsv', sep = '\\t', header = 0).drop_duplicates('topic_id')\n",
    "rdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = requests.append(rdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>initial_request</th>\n",
       "      <th>topic_desc</th>\n",
       "      <th>clarification_need</th>\n",
       "      <th>facet_id</th>\n",
       "      <th>facet_desc</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Tell me about Obama family tree.</td>\n",
       "      <td>Find information on President Barack Obama\\'s ...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0001</td>\n",
       "      <td>Find the TIME magazine photo essay \"Barack Oba...</td>\n",
       "      <td>Q00384</td>\n",
       "      <td>are you interested in seeing barack obamas family</td>\n",
       "      <td>yes am interested in obamas family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>102</td>\n",
       "      <td>What is Fickle Creek Farm</td>\n",
       "      <td>Find general information about Fickle Creek Fa...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0014</td>\n",
       "      <td>Find general information about Fickle Creek Fa...</td>\n",
       "      <td>Q00059</td>\n",
       "      <td>are you going to purchase anything there</td>\n",
       "      <td>i dont know yet i just want general info about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>105</td>\n",
       "      <td>Tell me about sonoma county medical services.</td>\n",
       "      <td>What medical services are available in Sonoma ...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0025</td>\n",
       "      <td>What medical services are available in Sonoma ...</td>\n",
       "      <td>Q00457</td>\n",
       "      <td>are you interested in the human services depar...</td>\n",
       "      <td>no i am looking for doctors or hospitals in so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>108</td>\n",
       "      <td>Tell me about of Ralph Owen Brester.</td>\n",
       "      <td>Find biographical information about Ralph Owen...</td>\n",
       "      <td>1</td>\n",
       "      <td>F0037</td>\n",
       "      <td>Find biographical information about Ralph Owen...</td>\n",
       "      <td>Q00297</td>\n",
       "      <td>are you interested in learning more about ralp...</td>\n",
       "      <td>yes and his biography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>109</td>\n",
       "      <td>I'm looking for information about mayo clinic ...</td>\n",
       "      <td>What medical services are available at the May...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0040</td>\n",
       "      <td>What medical services are available at the May...</td>\n",
       "      <td>Q00256</td>\n",
       "      <td>are you interested in jobs at mayo clinic jack...</td>\n",
       "      <td>no im interested in services provided at mayo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>51</td>\n",
       "      <td>Tell me more about horse hooves</td>\n",
       "      <td>Find information about horse hooves, their car...</td>\n",
       "      <td>2</td>\n",
       "      <td>F0858</td>\n",
       "      <td>Find information about horses' hooves and how ...</td>\n",
       "      <td>Q00025</td>\n",
       "      <td>are you asking about a horses feet</td>\n",
       "      <td>yes about horse hooves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>79</td>\n",
       "      <td>tell me about Voyager</td>\n",
       "      <td>Find information about the NASA Voyager spacec...</td>\n",
       "      <td>4</td>\n",
       "      <td>F0981</td>\n",
       "      <td>Find the homepage for the NASA Voyager mission.</td>\n",
       "      <td>Q00453</td>\n",
       "      <td>are you interested in the history of the voyager</td>\n",
       "      <td>no just take me to the homepage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>83</td>\n",
       "      <td>tell me about memory</td>\n",
       "      <td>Find information about human memory.</td>\n",
       "      <td>4</td>\n",
       "      <td>F0998</td>\n",
       "      <td>Find information about human memory.</td>\n",
       "      <td>Q00176</td>\n",
       "      <td>are you interested in computer memory</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>256</td>\n",
       "      <td>Who is the patron saint of mental illness?</td>\n",
       "      <td>Who is the patron saint of mental illness?</td>\n",
       "      <td>1</td>\n",
       "      <td>F0609</td>\n",
       "      <td>Who is the patron saint of mental illness?</td>\n",
       "      <td>Q00304</td>\n",
       "      <td>are you interested in learning the back story ...</td>\n",
       "      <td>im interested in learning who it is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305</th>\n",
       "      <td>292</td>\n",
       "      <td>i'm interested in history of the electronic me...</td>\n",
       "      <td>Find information on how the electronic medical...</td>\n",
       "      <td>3</td>\n",
       "      <td>F0745</td>\n",
       "      <td>Find information on how the electronic medical...</td>\n",
       "      <td>Q00118</td>\n",
       "      <td>are you interested in a specific time when ele...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic_id                                    initial_request  \\\n",
       "0            1                   Tell me about Obama family tree.   \n",
       "39         102                          What is Fickle Creek Farm   \n",
       "84         105      Tell me about sonoma county medical services.   \n",
       "120        108               Tell me about of Ralph Owen Brester.   \n",
       "159        109  I'm looking for information about mayo clinic ...   \n",
       "...        ...                                                ...   \n",
       "2120        51                    Tell me more about horse hooves   \n",
       "2195        79                              tell me about Voyager   \n",
       "2251        83                               tell me about memory   \n",
       "2293       256         Who is the patron saint of mental illness?   \n",
       "2305       292  i'm interested in history of the electronic me...   \n",
       "\n",
       "                                             topic_desc  clarification_need  \\\n",
       "0     Find information on President Barack Obama\\'s ...                   2   \n",
       "39    Find general information about Fickle Creek Fa...                   2   \n",
       "84    What medical services are available in Sonoma ...                   2   \n",
       "120   Find biographical information about Ralph Owen...                   1   \n",
       "159   What medical services are available at the May...                   2   \n",
       "...                                                 ...                 ...   \n",
       "2120  Find information about horse hooves, their car...                   2   \n",
       "2195  Find information about the NASA Voyager spacec...                   4   \n",
       "2251               Find information about human memory.                   4   \n",
       "2293         Who is the patron saint of mental illness?                   1   \n",
       "2305  Find information on how the electronic medical...                   3   \n",
       "\n",
       "     facet_id                                         facet_desc question_id  \\\n",
       "0       F0001  Find the TIME magazine photo essay \"Barack Oba...      Q00384   \n",
       "39      F0014  Find general information about Fickle Creek Fa...      Q00059   \n",
       "84      F0025  What medical services are available in Sonoma ...      Q00457   \n",
       "120     F0037  Find biographical information about Ralph Owen...      Q00297   \n",
       "159     F0040  What medical services are available at the May...      Q00256   \n",
       "...       ...                                                ...         ...   \n",
       "2120    F0858  Find information about horses' hooves and how ...      Q00025   \n",
       "2195    F0981    Find the homepage for the NASA Voyager mission.      Q00453   \n",
       "2251    F0998               Find information about human memory.      Q00176   \n",
       "2293    F0609         Who is the patron saint of mental illness?      Q00304   \n",
       "2305    F0745  Find information on how the electronic medical...      Q00118   \n",
       "\n",
       "                                               question  \\\n",
       "0     are you interested in seeing barack obamas family   \n",
       "39             are you going to purchase anything there   \n",
       "84    are you interested in the human services depar...   \n",
       "120   are you interested in learning more about ralp...   \n",
       "159   are you interested in jobs at mayo clinic jack...   \n",
       "...                                                 ...   \n",
       "2120                 are you asking about a horses feet   \n",
       "2195   are you interested in the history of the voyager   \n",
       "2251              are you interested in computer memory   \n",
       "2293  are you interested in learning the back story ...   \n",
       "2305  are you interested in a specific time when ele...   \n",
       "\n",
       "                                                 answer  \n",
       "0                    yes am interested in obamas family  \n",
       "39    i dont know yet i just want general info about...  \n",
       "84    no i am looking for doctors or hospitals in so...  \n",
       "120                               yes and his biography  \n",
       "159   no im interested in services provided at mayo ...  \n",
       "...                                                 ...  \n",
       "2120                             yes about horse hooves  \n",
       "2195                    no just take me to the homepage  \n",
       "2251                                                 no  \n",
       "2293                im interested in learning who it is  \n",
       "2305                                                yes  \n",
       "\n",
       "[237 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('retrieved_docs_encoded.pkl', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K0m \u001b[K"
     ]
    }
   ],
   "source": [
    "docs = {}\n",
    "with yaspin().arc:\n",
    "    while True:\n",
    "        try:\n",
    "            data = pickle.load(f)\n",
    "            tid = list(data.keys())[0]\n",
    "            docs[tid] = list(data.values())[0]\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ks = list(docs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tids = requests['topic_id'].to_numpy(dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tids = np.intersect1d(tids, np.array(ks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.zeros((len(tids), num_docs, embed_size))\n",
    "cosines = torch.zeros((len(tids), num_docs, num_docs))\n",
    "labels = torch.LongTensor(torch.zeros(len(tids)).long())\n",
    "init_qrs = torch.zeros((len(tids), init_query_embed_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([187, 50, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7eeba9df9f643ba98e98d4f03ec81bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=187.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(tids))):\n",
    "    tid = tids[i]\n",
    "    enc = docs[tid]['encoded_docs'][:50]\n",
    "    enc = np.array(enc)\n",
    "    csml = cosine_similarity(enc)\n",
    "    inputs[i] = torch.Tensor(enc)\n",
    "    A = torch.Tensor(csml)\n",
    "    S = torch.sum(A, axis = 1)\n",
    "    D = torch.diag(torch.sum(A, axis = 1))\n",
    "    D_ = torch.Tensor(fractional_matrix_power(D, -0.5))\n",
    "    A_ = torch.chain_matmul(D_, A, D_)\n",
    "    cosines[i] = A_\n",
    "    labels[i] = df.loc[df['topic_id'] == tid]['clarification_need'].to_numpy(dtype = np.int_)[0]\n",
    "    init_qr = df.loc[df['topic_id'] == tid]['initial_request'].to_numpy(dtype = str)[0]\n",
    "    init_qrs[i] = torch.Tensor(bert_model.encode(init_qr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([187, 768])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_qrs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.LongTensor(labels.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 2, 3, 4, 2, 3, 2, 3, 2, 2, 3, 4, 1, 2, 2, 1, 2, 2, 2, 2, 3, 3, 2,\n",
       "        2, 3, 2, 3, 3, 3, 2, 3, 2, 3, 3, 2, 4, 2, 3, 2, 4, 3, 2, 4, 1, 2, 3, 1,\n",
       "        4, 4, 2, 4, 3, 3, 1, 2, 4, 3, 4, 4, 3, 2, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3,\n",
       "        2, 4, 2, 4, 4, 4, 4, 2, 3, 3, 2, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 3,\n",
       "        2, 3, 2, 3, 3, 2, 3, 2, 2, 2, 4, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 2, 2, 3,\n",
       "        2, 2, 4, 4, 3, 3, 3, 3, 3, 2, 2, 3, 3, 2, 4, 2, 2, 3, 1, 3, 2, 3, 2, 2,\n",
       "        3, 4, 3, 3, 1, 4, 3, 3, 1, 3, 2, 2, 1, 3, 2, 2, 2, 3, 2, 1, 1, 1, 2, 3,\n",
       "        1, 2, 1, 1, 2, 1, 3, 4, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0312)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.max(cosines[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_tids = rdev['topic_id'].to_numpy(dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_labels = rdev['clarification_need'].to_numpy(dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_inputs = torch.zeros((len(dev_tids), num_docs, embed_size))\n",
    "dev_cosines = torch.zeros((len(dev_tids), num_docs, num_docs))\n",
    "dev_init_qrs = torch.zeros((len(dev_tids), init_query_embed_size))\n",
    "dev_labels = torch.LongTensor(torch.zeros(len(dev_tids)).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14c7ec3da1f48689765a2e5abe00f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(dev_tids))):\n",
    "    tid = dev_tids[i]\n",
    "    enc = docs[tid]['encoded_docs'][:50]\n",
    "    enc = np.array(enc)\n",
    "    csml = cosine_similarity(enc)\n",
    "    dev_inputs[i] = torch.Tensor(enc)\n",
    "    A = torch.Tensor(csml)\n",
    "    S = torch.sum(A, axis = 1)\n",
    "    D = torch.diag(torch.sum(A, axis = 1))\n",
    "    D_ = torch.Tensor(fractional_matrix_power(D, -0.5))\n",
    "    A_ = torch.chain_matmul(D_, A, D_)\n",
    "    dev_cosines[i] = A_\n",
    "    dev_labels[i] = df.loc[df['topic_id'] == tid]['clarification_need'].to_numpy(dtype = np.int_)[0]\n",
    "    init_qr = rdev.loc[rdev['topic_id'] == tid]['initial_request'].to_numpy(dtype = str)[0]\n",
    "    dev_init_qrs[i] = torch.Tensor(bert_model.encode(init_qr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_labels = torch.LongTensor(dev_labels.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_init_qrs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(inputs, cosines, init_qrs, labels)\n",
    "dev_dataset = torch.utils.data.TensorDataset(dev_inputs, dev_cosines, dev_init_qrs, dev_labels)\n",
    "dataset = torch.utils.data.ConcatDataset([train_dataset, dev_dataset])\n",
    "kfold = KFold(n_splits = k_folds, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, batch_size):\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    results = {}\n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "        print(f\"Fold: {fold}\")\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "        test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "        train_loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, sampler = train_subsampler)\n",
    "        test_loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, sampler = test_subsampler)\n",
    "        model = AmbiguityNetwork()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay = 0.1)\n",
    "        curr_count = 0\n",
    "        acc = 0\n",
    "        curr_loss = 0\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            model.train()\n",
    "            for idx, data in enumerate(train_loader):\n",
    "                nf, A, iqs, tgts = data\n",
    "                tgts = tgts - 1\n",
    "                tgts = torch.LongTensor(tgts)\n",
    "                preds = model(nf, A, iqs)\n",
    "                loss = loss_fn(preds, tgts)\n",
    "                m = torch.nn.Softmax()\n",
    "                npreds = m(preds).detach().numpy()\n",
    "                class_preds = np.argmax(npreds, axis = 1)\n",
    "                acc += accuracy_score(tgts.detach().numpy(), class_preds)\n",
    "                curr_loss += loss.item()\n",
    "                curr_count += 1\n",
    "                model.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        curr_loss = curr_loss/curr_count\n",
    "        acc = acc/curr_count\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            model.eval()\n",
    "            val_acc = 0\n",
    "            val_loss = 0\n",
    "            val_prec = 0\n",
    "            val_rec = 0\n",
    "            val_f1 = 0\n",
    "            total = 0\n",
    "            count = 0\n",
    "            for dev_idx, dev_data in enumerate(test_loader):\n",
    "                nf, A, iqs, dev_labels = dev_data\n",
    "                val_preds = model(nf, A, iqs)\n",
    "                m = torch.nn.Softmax()\n",
    "                val_npreds = m(val_preds).detach().numpy()\n",
    "                class_preds = np.argmax(val_npreds, axis = 1)\n",
    "                class_preds = class_preds + 1\n",
    "                val_acc += accuracy_score(dev_labels, class_preds)\n",
    "                val_loss += log_loss(dev_labels, val_npreds, labels = [1,2,3,4])\n",
    "                val_prec += precision_score(dev_labels, class_preds, average = 'weighted')\n",
    "                val_rec += recall_score(dev_labels, class_preds, average = 'weighted')\n",
    "                val_f1 += f1_score(dev_labels, class_preds, average = 'weighted')\n",
    "                count += 1\n",
    "        results[fold] = {\n",
    "            'training_loss': curr_loss,\n",
    "            'training_acc': acc,\n",
    "            'validation_loss': val_loss/count,\n",
    "            'validation_acc': val_acc/count,\n",
    "            'precision': val_prec/count,\n",
    "            'recall': val_rec/count,\n",
    "            'f1': val_f1/count\n",
    "        }\n",
    "        print(f\"Loss: {curr_loss}, training acc: {acc}, validation_loss: {val_loss/count}, validation acc: {val_acc/count}\")\n",
    "\n",
    "    train_acc = 0\n",
    "    train_loss = 0\n",
    "    val_acc = 0\n",
    "    val_loss = 0\n",
    "    prec = 0\n",
    "    f1 = 0\n",
    "    rec = 0\n",
    "    for key, value in results.items():\n",
    "        train_acc += value['training_acc']\n",
    "        train_loss += value['training_loss']\n",
    "        val_acc += value['validation_acc']\n",
    "        val_loss += value['validation_loss']\n",
    "        prec += value['precision']\n",
    "        rec += value['recall']\n",
    "        f1 += value['f1']\n",
    "    print('Final Metrics:')\n",
    "    print(f\"Training loss: {train_loss/k_folds}, Training acc: {train_acc/k_folds}, Validation loss: {val_loss/k_folds}, Validation acc: {val_acc/k_folds}, Precision: {prec/k_folds}, Recall: {rec/k_folds}, F1: {f1/k_folds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35430aac04946f4bc1b960541e6a715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-867ad9dd180e>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  npreds = m(preds).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6931842352371467, training acc: 0.7921520467836296, validation_loss: 1.5840927896276118, validation acc: 0.29\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58190bd8a9ab4f5596c9c0c8dc1d8935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-867ad9dd180e>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  npreds = m(preds).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.7013700803643779, training acc: 0.7874619883040965, validation_loss: 1.4447873000428082, validation acc: 0.41500000000000004\n",
      "Fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4396b7d3d0845e5b95cbf8a041ec903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-867ad9dd180e>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  npreds = m(preds).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.7341065242886543, training acc: 0.7782631578947398, validation_loss: 1.3392763278314046, validation acc: 0.36571428571428577\n",
      "Fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ebf79727de49be8128fa5bf3d1aa53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-867ad9dd180e>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  npreds = m(preds).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.7244401293992996, training acc: 0.7764736842105293, validation_loss: 1.395842742409025, validation acc: 0.3885714285714286\n",
      "Fold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e70cc051c584e7a8cb8bb9f0102cc5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-867ad9dd180e>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  npreds = m(preds).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.713829603759866, training acc: 0.7905789473684234, validation_loss: 1.4415476806036065, validation acc: 0.30857142857142855\n",
      "Final Metrics:\n",
      "Training loss: 0.7133861146098689, Training acc: 0.7849859649122837, Validation loss: 1.441109368102891, Validation acc: 0.35357142857142854, Precision: 0.35049047619047624, Recall: 0.35357142857142854, F1: 0.32756310832025115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-36-867ad9dd180e>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  val_npreds = m(val_preds).detach().numpy()\n",
      "D:\\Installations\\Python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train(100, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AmbiguityNetwork()\n",
    "model.load_state_dict(torch.load('saved_model_graphcnn.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model(dev_inputs, dev_cosines, dev_init_qrs)\n",
    "m = torch.nn.Softmax()\n",
    "val_npreds = m(val_preds).detach().numpy()\n",
    "class_preds = np.argmax(val_npreds, axis = 1)\n",
    "class_preds = class_preds + 1\n",
    "prec_score = precision_score(dev_labels, class_preds, average = 'weighted')\n",
    "rec_score = recall_score(dev_labels, class_preds, average = 'weighted')\n",
    "f1 = f1_score(dev_labels, class_preds, average = 'weighted')\n",
    "print(prec_score, rec_score, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(dev_inputs, dev_cosines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = torch.nn.Softmax()\n",
    "\n",
    "preds = m(preds).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_preds = np.argmax(preds, axis = 1)\n",
    "class_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(class_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_preds = class_preds + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outs = [(dev_tids[i], class_preds[i]) for i in range(len(preds))]\n",
    "outs = np.array(outs)\n",
    "outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('preds_dev_doc2vec_cosine_10gcn_10gcn.txt', outs, fmt=\"%s %s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python clariq_eval_tool.py --eval_task clarification_need \\\n",
    "                                 --data_dir ./data/ \\\n",
    "                                 --experiment_type dev \\\n",
    "                                 --run_file preds_dev_doc2vec_cosine_10gcn_10gcn.txt \\\n",
    "                                 --out_file out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bit54af622977484619b47ea42e3ff533e7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
